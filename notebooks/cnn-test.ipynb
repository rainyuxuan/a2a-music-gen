{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.trainer import Trainer\n",
    "from src.models.cnn import CNN\n",
    "from src.data import WaveDataset, SpectrogramDataset\n",
    "from src.features import WaveProcessor, WaveProcessorConfig\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = os.getcwd().replace(\"\\\\\", \"/\")\n",
    "processed_dir = f\"{wdir}/data/processed\"\n",
    "sr = 44100 // 8\n",
    "wav_dataset = WaveDataset(f\"{wdir}/data/raw/train_data\", sr=sr, max_sec=30)\n",
    "wpconfig = WaveProcessorConfig(sr=sr)\n",
    "wp = WaveProcessor(wpconfig)\n",
    "\n",
    "wav_loader = DataLoader(wav_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for b, (xs, ys, fnames) in enumerate(wav_loader):\n",
    "#     for x, y, fname in zip(xs, ys, fnames):\n",
    "#         input_spec = wp.wav2freq(x)\n",
    "#         label_spec = wp.wav2freq(y)\n",
    "\n",
    "#         SpectrogramDataset.save(input_spec, f\"{processed_dir}/train_data\", fname)\n",
    "#         SpectrogramDataset.save(\n",
    "#             label_spec, f\"{processed_dir}/train_labels\", fname, is_label=True\n",
    "#         )\n",
    "#         SpectrogramDataset.save_metadata(\n",
    "#             wpconfig.to_dict(), f\"{processed_dir}/train_meta\", fname\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTrainer(Trainer):\n",
    "    def create_model(self, token_size, seq_size, n_layer, out_size) -> None:\n",
    "        self.model = CNN(token_size, seq_size, n_layer, out_size)\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        weight_decay: float,\n",
    "        learning_rate: float,\n",
    "        num_epochs: int,\n",
    "        device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        self.model = self.model.to(device)  # move model to GPU if applicable\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(\n",
    "            self.model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "        history = []\n",
    "\n",
    "        for e in range(num_epochs):\n",
    "            train_loss = 0.0\n",
    "            val_loss = 0.0\n",
    "\n",
    "            train_acc = 0\n",
    "            val_acc = 0\n",
    "\n",
    "            self.model.train()\n",
    "\n",
    "            for data, target, fname in self.dataloaders[\"train\"]:\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                # Clear gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = torch.empty((target.shape[0], target.shape[1], target.shape[2]), device=device)\n",
    "                batch_loss = 0.0\n",
    "                for i in range(target.shape[-1]):\n",
    "                    # Predicted outputs\n",
    "                    cur_output = self.model(data)\n",
    "\n",
    "                    # Loss and backpropagation of gradients\n",
    "                    loss = criterion(cur_output, target[:, :, i]) / target.shape[1]\n",
    "                    loss.backward()\n",
    "                    batch_loss += loss.item()\n",
    "\n",
    "                    output[:, :, i] = cur_output\n",
    "                    data = torch.cat((data[:, :, 1:], torch.unsqueeze(target[:, :, i], dim= -1)), dim=-1)\n",
    "\n",
    "                # Update the parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # Track train loss by multiplying average loss by number of examples in batch\n",
    "                train_loss += batch_loss * data.size(0)\n",
    "                # check target have same shape as output\n",
    "                target = target.data.view_as(output)\n",
    "                accuracy = self.get_accuracy(output, target)\n",
    "                # Multiply average accuracy times the number of examples in batch\n",
    "                train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                self.model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target, fname in self.dataloaders[\"val\"]:\n",
    "                    # Tensors to gpu\n",
    "                    if torch.cuda.is_available():\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = self.model.generate(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target)\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    val_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # check target have same shape as output\n",
    "                    target = target.data.view_as(output)\n",
    "                    accuracy = self.get_accuracy(output, target)\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    val_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(self.dataloaders[\"train\"].dataset)\n",
    "                val_loss = val_loss / len(self.dataloaders[\"val\"].dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(self.dataloaders[\"train\"].dataset)\n",
    "                val_acc = val_acc / len(self.dataloaders[\"val\"].dataset)\n",
    "\n",
    "                print(\n",
    "                    f\"\\nEpoch: {e} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {val_loss:.4f}\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"\\t \\tTraining Accuracy: {100 * train_acc:.2f}% \\tValidation Accuracy: {100 * val_acc:.2f}%\"\n",
    "                )\n",
    "                history.append([train_loss, val_loss, train_acc, val_acc])\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            history, columns=[\"train_loss\", \"val_loss\", \"train_acc\", \"val_acc\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dataset = SpectrogramDataset(\n",
    "    f\"{processed_dir}/train_data\", label_dir=f\"{processed_dir}/train_labels\"\n",
    ")\n",
    "\n",
    "token_size = spec_dataset[0][0].shape[0]\n",
    "seq_size = spec_dataset[0][0].shape[1]\n",
    "out_size = spec_dataset[0][1].shape[1]\n",
    "\n",
    "train_set, val_set = random_split(spec_dataset, [0.8, 0.2])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=5, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0 \tTraining Loss: 53.5987 \tValidation Loss: 81.5682\n",
      "\t \tTraining Accuracy: 29.08% \tValidation Accuracy: 32.77%\n",
      "\n",
      "Epoch: 1 \tTraining Loss: 53.2315 \tValidation Loss: 144.7879\n",
      "\t \tTraining Accuracy: 32.84% \tValidation Accuracy: 33.13%\n",
      "\n",
      "Epoch: 2 \tTraining Loss: 52.8900 \tValidation Loss: 79.2473\n",
      "\t \tTraining Accuracy: 32.55% \tValidation Accuracy: 32.35%\n",
      "\n",
      "Epoch: 3 \tTraining Loss: 52.6506 \tValidation Loss: 118.3015\n",
      "\t \tTraining Accuracy: 31.72% \tValidation Accuracy: 30.95%\n",
      "\n",
      "Epoch: 4 \tTraining Loss: 52.4387 \tValidation Loss: 74.6868\n",
      "\t \tTraining Accuracy: 29.93% \tValidation Accuracy: 27.42%\n",
      "\n",
      "Epoch: 5 \tTraining Loss: 52.2427 \tValidation Loss: 74.8083\n",
      "\t \tTraining Accuracy: 29.70% \tValidation Accuracy: 27.29%\n",
      "\n",
      "Epoch: 6 \tTraining Loss: 51.6361 \tValidation Loss: 6551.7528\n",
      "\t \tTraining Accuracy: 29.90% \tValidation Accuracy: 23.94%\n",
      "\n",
      "Epoch: 7 \tTraining Loss: 51.1751 \tValidation Loss: 74.2440\n",
      "\t \tTraining Accuracy: 28.70% \tValidation Accuracy: 23.06%\n",
      "\n",
      "Epoch: 8 \tTraining Loss: 50.7906 \tValidation Loss: inf\n",
      "\t \tTraining Accuracy: 27.78% \tValidation Accuracy: 17.74%\n",
      "\n",
      "Epoch: 9 \tTraining Loss: 50.6840 \tValidation Loss: 74.3927\n",
      "\t \tTraining Accuracy: 27.60% \tValidation Accuracy: 20.67%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.598694</td>\n",
       "      <td>81.568247</td>\n",
       "      <td>0.290772</td>\n",
       "      <td>0.327663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.231481</td>\n",
       "      <td>144.787884</td>\n",
       "      <td>0.328352</td>\n",
       "      <td>0.331297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.890021</td>\n",
       "      <td>79.247265</td>\n",
       "      <td>0.325539</td>\n",
       "      <td>0.323512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.650615</td>\n",
       "      <td>118.301543</td>\n",
       "      <td>0.317167</td>\n",
       "      <td>0.309474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.438657</td>\n",
       "      <td>74.686847</td>\n",
       "      <td>0.299343</td>\n",
       "      <td>0.274247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52.242709</td>\n",
       "      <td>74.808338</td>\n",
       "      <td>0.297029</td>\n",
       "      <td>0.272946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51.636094</td>\n",
       "      <td>6551.752848</td>\n",
       "      <td>0.299007</td>\n",
       "      <td>0.239435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51.175065</td>\n",
       "      <td>74.244013</td>\n",
       "      <td>0.287027</td>\n",
       "      <td>0.230575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50.790633</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.277845</td>\n",
       "      <td>0.177391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50.683963</td>\n",
       "      <td>74.392654</td>\n",
       "      <td>0.275984</td>\n",
       "      <td>0.206731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss     val_loss  train_acc   val_acc\n",
       "0   53.598694    81.568247   0.290772  0.327663\n",
       "1   53.231481   144.787884   0.328352  0.331297\n",
       "2   52.890021    79.247265   0.325539  0.323512\n",
       "3   52.650615   118.301543   0.317167  0.309474\n",
       "4   52.438657    74.686847   0.299343  0.274247\n",
       "5   52.242709    74.808338   0.297029  0.272946\n",
       "6   51.636094  6551.752848   0.299007  0.239435\n",
       "7   51.175065    74.244013   0.287027  0.230575\n",
       "8   50.790633          inf   0.277845  0.177391\n",
       "9   50.683963    74.392654   0.275984  0.206731"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = CNNTrainer()\n",
    "trainer.create_model(token_size, seq_size, 3, out_size)\n",
    "trainer.set_dataloaders(train_loader, val_loader, None)\n",
    "trainer.train(0.001, 0.001, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
